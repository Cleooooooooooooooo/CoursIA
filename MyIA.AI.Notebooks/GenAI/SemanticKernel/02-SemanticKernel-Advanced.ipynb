{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Kernel : Chat, Planners, Memory, Hugging Face, Groundedness & Multi-Result\n",
    "\n",
    "Dans ce notebook, nous allons explorer plusieurs fonctionnalités avancées de **Semantic Kernel** :\n",
    "\n",
    "1. **Chat basique** avec Kernel Arguments (historique et contexte via un objet `KernelArguments`).\n",
    "2. **Planners** (Sequential, Stepwise Function Calling) pour orchestrer dynamiquement des actions selon un but donné.\n",
    "3. **Mémoire** & Embeddings (VolatileMemoryStore ou connecteurs externes) pour stocker des informations sémantiques.\n",
    "4. **Hugging Face** : Intégration de modèles (texte, embeddings) en local ou depuis le Hub.\n",
    "5. **Groundedness Checking** : vérification et ajustement du contenu pour éviter des “fabrications non justifiées”.\n",
    "6. **Multi-Result** : récupération de plusieurs réponses pour un même prompt (OpenAI, Azure, Hugging Face).\n",
    "\n",
    "Ce notebook est une **synthèse** des exemples dispersés dans différents notebooks, présentés sous forme de cellules Markdown et Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: semantic-kernel in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.20.0)\n",
      "Requirement already satisfied: aiohttp~=3.8 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel) (3.11.10)\n",
      "Requirement already satisfied: cloudevents~=1.0 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel) (1.11.0)\n",
      "Requirement already satisfied: pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.11,>=2.0 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel) (2.9.2)\n",
      "Requirement already satisfied: pydantic-settings~=2.0 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel) (2.7.0)\n",
      "Requirement already satisfied: defusedxml~=0.7 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel) (0.7.1)\n",
      "Requirement already satisfied: azure-identity~=1.13 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel) (1.19.0)\n",
      "Requirement already satisfied: numpy>=1.25.0 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel) (1.26.4)\n",
      "Requirement already satisfied: openai~=1.0 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel) (1.57.4)\n",
      "Requirement already satisfied: openapi_core<0.20,>=0.18 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel) (0.19.4)\n",
      "Requirement already satisfied: opentelemetry-api~=1.24 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-sdk~=1.24 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel) (1.29.0)\n",
      "Requirement already satisfied: prance~=23.6.21.0 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel) (23.6.21.0)\n",
      "Requirement already satisfied: pybars4~=0.9 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel) (0.9.13)\n",
      "Requirement already satisfied: jinja2~=3.1 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel) (3.1.4)\n",
      "Requirement already satisfied: nest-asyncio~=1.6 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel) (1.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (1.18.3)\n",
      "Requirement already satisfied: azure-core>=1.31.0 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-identity~=1.13->semantic-kernel) (1.32.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-identity~=1.13->semantic-kernel) (42.0.8)\n",
      "Requirement already satisfied: msal>=1.30.0 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-identity~=1.13->semantic-kernel) (1.31.1)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-identity~=1.13->semantic-kernel) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-identity~=1.13->semantic-kernel) (4.12.2)\n",
      "Requirement already satisfied: deprecation<3.0,>=2.0 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cloudevents~=1.0->semantic-kernel) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2~=3.1->semantic-kernel) (3.0.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai~=1.0->semantic-kernel) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai~=1.0->semantic-kernel) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai~=1.0->semantic-kernel) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai~=1.0->semantic-kernel) (0.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai~=1.0->semantic-kernel) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai~=1.0->semantic-kernel) (4.67.1)\n",
      "Requirement already satisfied: isodate in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.7.2)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (4.23.0)\n",
      "Requirement already satisfied: jsonschema-path<0.4.0,>=0.3.1 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.3.3)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (10.5.0)\n",
      "Requirement already satisfied: openapi-schema-validator<0.7.0,>=0.6.0 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.6.2)\n",
      "Requirement already satisfied: openapi-spec-validator<0.8.0,>=0.7.1 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.7.1)\n",
      "Requirement already satisfied: parse in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (1.20.2)\n",
      "Requirement already satisfied: werkzeug in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (3.1.3)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-api~=1.24->semantic-kernel) (1.2.15)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-api~=1.24->semantic-kernel) (8.5.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-sdk~=1.24->semantic-kernel) (0.50b0)\n",
      "Requirement already satisfied: chardet>=3.0 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prance~=23.6.21.0->semantic-kernel) (5.2.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.10 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prance~=23.6.21.0->semantic-kernel) (0.18.6)\n",
      "Requirement already satisfied: requests>=2.25 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prance~=23.6.21.0->semantic-kernel) (2.32.3)\n",
      "Requirement already satisfied: six~=1.15 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prance~=23.6.21.0->semantic-kernel) (1.16.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prance~=23.6.21.0->semantic-kernel) (24.1)\n",
      "Requirement already satisfied: PyMeta3>=0.5.1 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pybars4~=0.9->semantic-kernel) (0.5.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.11,>=2.0->semantic-kernel) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.11,>=2.0->semantic-kernel) (2.23.4)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic-settings~=2.0->semantic-kernel) (1.0.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->openai~=1.0->semantic-kernel) (3.10)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cryptography>=2.5->azure-identity~=1.13->semantic-kernel) (1.17.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api~=1.24->semantic-kernel) (1.17.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai~=1.0->semantic-kernel) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai~=1.0->semantic-kernel) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai~=1.0->semantic-kernel) (0.14.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api~=1.24->semantic-kernel) (3.21.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.22.3)\n",
      "Requirement already satisfied: PyYAML>=5.1 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (6.0.2)\n",
      "Requirement already satisfied: pathable<0.5.0,>=0.4.1 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (0.4.3)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity~=1.13->semantic-kernel) (2.10.1)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from msal-extensions>=1.2.0->azure-identity~=1.13->semantic-kernel) (2.10.1)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.1.4)\n",
      "Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic-kernel) (1.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.25->prance~=23.6.21.0->semantic-kernel) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.25->prance~=23.6.21.0->semantic-kernel) (2.2.3)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ruamel.yaml>=0.17.10->prance~=23.6.21.0->semantic-kernel) (0.2.12)\n",
      "Requirement already satisfied: colorama in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>4->openai~=1.0->semantic-kernel) (0.4.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity~=1.13->semantic-kernel) (2.22)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\administrateur.000\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from portalocker<3,>=1.4->msal-extensions>=1.2.0->azure-identity~=1.13->semantic-kernel) (308)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Imports et installation OK.\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cellule : Installation & Imports\n",
    "# ============================\n",
    "\n",
    "# N'installez qu'une seule fois si nécessaire\n",
    "%pip install -U semantic-kernel\n",
    "\n",
    "# Imports de base\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.functions import KernelArguments\n",
    "from semantic_kernel.contents import ChatHistory\n",
    "\n",
    "print(\"Imports et installation OK.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Bloc Markdown – Configuration du Kernel & .env\n",
    "\n",
    "```markdown\n",
    "### Configuration du Kernel\n",
    "\n",
    "Pour exécuter les exemples, on suppose que vous avez un fichier `.env` comportant vos clés d'API OpenAI / Azure OpenAI / Hugging Face.  \n",
    "Exemple `.env` :\n",
    "\n",
    "```\n",
    "GLOBAL_LLM_SERVICE=\"OpenAI\"        # ou AzureOpenAI, HuggingFace\n",
    "OPENAI_API_KEY=\"sk-...\"\n",
    "OPENAI_CHAT_MODEL_ID=\"gpt-3.5-turbo\"\n",
    "...\n",
    "```\n",
    "\n",
    "Le `Kernel` lira ces informations pour décider quel connecteur LLM utiliser.  \n",
    "Ensuite, nous ajouterons nos services (`OpenAIChatCompletion`, `AzureChatCompletion`, etc.) selon la variable `GLOBAL_LLM_SERVICE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service OpenAI configuré.\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cellule : Initialisation du Kernel\n",
    "# ============================\n",
    "\n",
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    OpenAIChatCompletion,\n",
    "    AzureChatCompletion\n",
    ")\n",
    "\n",
    "# On charge le .env\n",
    "load_dotenv()\n",
    "global_llm_service = os.getenv(\"GLOBAL_LLM_SERVICE\", \"AzureOpenAI\")\n",
    "\n",
    "# Initialisation du Kernel\n",
    "kernel = Kernel()\n",
    "\n",
    "if global_llm_service.lower() == \"openai\":\n",
    "    # Ajout du service OpenAI\n",
    "    kernel.add_service(\n",
    "        OpenAIChatCompletion(service_id=\"chatOpenAI\"),\n",
    "    )\n",
    "    print(\"Service OpenAI configuré.\")\n",
    "elif global_llm_service.lower() == \"huggingface\":\n",
    "    # Ajout du service HuggingFace\n",
    "    from semantic_kernel.connectors.ai.hugging_face import HuggingFaceTextCompletion\n",
    "    kernel.add_service(\n",
    "        HuggingFaceTextCompletion(\n",
    "            service_id=\"chatHF\",\n",
    "            ai_model_id=\"distilgpt2\", # ex. pour text-generation\n",
    "            task=\"text-generation\"\n",
    "        ),\n",
    "    )\n",
    "    print(\"Service Hugging Face configuré.\")\n",
    "else:\n",
    "    # Par défaut : Azure OpenAI\n",
    "    kernel.add_service(\n",
    "        AzureChatCompletion(service_id=\"chatAzure\"),\n",
    "    )\n",
    "    print(\"Service Azure OpenAI configuré.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Basique avec KernelArguments\n",
    "\n",
    "L'idée : on crée une fonction de chat qui prend :\n",
    "- l’historique de conversation (objet `ChatHistory`)\n",
    "- un `user_input`\n",
    "et on stocke le tout dans un `KernelArguments`.  \n",
    "\n",
    "Cela permet d'alimenter un prompt (via un template) qui contient la variable `history` et `user_input`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Utilisateur] : Salut, peux-tu me conseiller un livre sur la philosophie antique ?\n",
      "[ChatBot] : Salut ! Je te recommande \"La République\" de Platon. Ce dialogue explore la justice, la politique et la nature de l'âme, et il est fondamental pour comprendre la philosophie antique. Si tu cherches quelque chose de plus orienté vers les stoïciens, \" Méditations\" de Marc Aurèle est également une excellente lecture. Les deux ouvrages offrent des perspectives profondes sur la vie et la morale. Tu cherchais un genre particulier ou un auteur en particulier ?\n",
      "[Utilisateur] : Merci, tu peux détailler un peu plus la période concernée ?\n",
      "[ChatBot] : Bien sûr ! La philosophie antique s'étend principalement de la période présocratique (6e siècle av. J.-C.) jusqu'à la fin de l'Antiquité, vers le 6e siècle apr. J.-C. Cette époque englobe plusieurs courants de pensée et écoles :\n",
      "\n",
      "1. **Les Présocratiques** (6e-5e siècle av. J.-C.) : Ce sont les premiers penseurs grecs comme Thalès, Anaximène et Héraclite, qui s'interrogent sur la nature de l'univers et le principe fondamental des choses.\n",
      "\n",
      "2. **Socrate** (469-399 av. J.-C.) : Son approche dialectique et son insistance sur l'éthique influencent profondément la philosophie occidentale.\n",
      "\n",
      "3. **Platon** (427-347 av. J.-C.) : Élève de Socrate, il fonde l'Académie et aborde des thèmes variés tels que la justice, la beauté et la connaissance à travers ses dialogues.\n",
      "\n",
      "4. **Aristote** (384-322 av. J.-C.) : Élève de Platon, il développe une vaste gamme de sujets allant de la logique et la biologie à l'éthique et la politique. Son influence persiste jusqu'à aujourd'hui.\n",
      "\n",
      "5. **Les écoles hellénistiques** (3e siècle av. J.-C. - 3e siècle apr. J.-C.) : Ce sont des courants comme le stoïcisme (Sénèque, Épictète), l'épicurisme (Épicure) et le cynisme (Diogène), qui se concentrent souvent sur la vie pratique et la quête du bonheur.\n",
      "\n",
      "6. **Le néoplatonisme** (3e-6e siècle apr. J.-C.) : Une synthèse des pensées platoniciennes et des traditions religieuses, représentée par des penseurs comme Plotin.\n",
      "\n",
      "Ces périodes et écoles ont jeté les bases de la pensée occidentale et continuent d'influencer la philosophie contemporaine. Si tu souhaites explorer un aspect particulier ou un penseur spécifique, fais-le moi savoir !\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cellule : Extrait d'un Chat Minimal\n",
    "# ============================\n",
    "\n",
    "# Exemple de prompt\n",
    "chat_prompt = \"\"\"\n",
    "{{$history}}\n",
    "User: {{$user_input}}\n",
    "ChatBot:\n",
    "\"\"\"\n",
    "\n",
    "# Création d'une fonction sémantique \"chat\"\n",
    "from semantic_kernel.prompt_template import PromptTemplateConfig, InputVariable\n",
    "\n",
    "pt_config = PromptTemplateConfig(\n",
    "    template=chat_prompt,\n",
    "    name=\"chatFunction\",\n",
    "    template_format=\"semantic-kernel\",\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"user_input\", description=\"User's message\"),\n",
    "        InputVariable(name=\"history\", description=\"Conversation history\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_function = kernel.add_function(\n",
    "    function_name=\"chat\",\n",
    "    plugin_name=\"myChatPlugin\",\n",
    "    prompt_template_config=pt_config\n",
    ")\n",
    "\n",
    "chat_history = ChatHistory()\n",
    "chat_history.add_system_message(\"Vous êtes un chatbot utile spécialisé en recommandations de livres.\")\n",
    "\n",
    "async def chat_kernel(input_text: str):\n",
    "    print(f\"[Utilisateur] : {input_text}\")\n",
    "    response = await kernel.invoke(\n",
    "        chat_function,\n",
    "        KernelArguments(user_input=input_text, history=chat_history)\n",
    "    )\n",
    "    print(f\"[ChatBot] : {response}\")\n",
    "    # Mise à jour de l'historique\n",
    "    chat_history.add_user_message(input_text)\n",
    "    chat_history.add_assistant_message(str(response))\n",
    "\n",
    "\n",
    "# Test\n",
    "await chat_kernel(\"Salut, peux-tu me conseiller un livre sur la philosophie antique ?\")\n",
    "await chat_kernel(\"Merci, tu peux détailler un peu plus la période concernée ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planners : Orchestration Dynamique\n",
    "\n",
    "**SequentialPlanner** : Génère un plan sous forme de liste d’étapes (XML), chaque étape étant une fonction existante.  \n",
    "**FunctionCallingStepwisePlanner** : S'appuie sur OpenAI function-calling pour exécuter “pas à pas” (ReAct, MRKL).\n",
    "\n",
    "**Exemple d'usage** :\n",
    "1. Le *user* fournit un `goal`.\n",
    "2. Le planner trouve les fonctions (plugins sémantiques ou natifs) permettant d'accomplir ce but.\n",
    "3. Il exécute les étapes, éventuellement enchaînant *function calls*.\n",
    "\n",
    "Ci-dessous, un extrait minimal de code pour un `SequentialPlanner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plan généré par le SequentialPlanner :\n",
      "Étape 1 => None // myChatPlugin-chat\n",
      "Étape 2 => None // myChatPlugin-chat\n",
      "\n",
      "=== Résultat du plan ===\n",
      "DANS LES JARDINS OÙ L’AUBE S’ÉVEILLE,  \n",
      "LES FLEURS DANSENT SOUS LE SOUFFLE LÉGER,  \n",
      "LE CIEL, PEINT D’OR, ÉTEND SA MERVEILLE,  \n",
      "ET LE VENT MURMURE DES VERS ENFLAMMÉS.  \n",
      "\n",
      "Ô TENDRE AMOUR, ÉTOILE DE MES NUITS,  \n",
      "DE TON REGARD, JE SUIS ÉPERDUMENT ÉPRIS,  \n",
      "COMME L'ABEILLE AU DOUX NECTAR, JE SUIS,  \n",
      "EN TON SOURIRE, JE TROUVE MON ABRI.  \n",
      "\n",
      "LES OMBRES DU TEMPS, TELLES DES VAGUES FUGACES,  \n",
      "EMPORTENT LES RÊVES, MAIS JAMAIS TON IMAGE,  \n",
      "CAR DANS L'ÉCRIN DE MON CŒUR, TU FAIS TA PLACE,  \n",
      "ÉTERNITÉ, À TRAVERS MILLE ÂGES.  \n",
      "\n",
      "QUANT AUX PLEURS DE L'ABSENCE, JE FAIS RIPOSTE,  \n",
      "AMOUR, SOIS MON PHARE, DANS LA BRUME QUI S'IMPOSE.  \n",
      "AVEC DES RIMES, À JAMAIS JE T’AUGUSTE,  \n",
      "UNIS POUR L'ÉTERNITÉ, TEL UN VERS QUI EXPLOSE.  \n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cellule : Sequential Planner\n",
    "# ============================\n",
    "\n",
    "from semantic_kernel.planners import SequentialPlanner\n",
    "\n",
    "planner = SequentialPlanner(kernel, service_id=\"chatOpenAI\")  # adapter selon ton service\n",
    "user_goal = \"\"\"\n",
    "Demain c'est la Saint-Valentin. Je veux composer un poème\n",
    "dans le style de Shakespeare, en français, puis convertir\n",
    "le texte en majuscules.\n",
    "\"\"\"\n",
    "\n",
    "seq_plan = await planner.create_plan(user_goal)\n",
    "print(\"Plan généré par le SequentialPlanner :\")\n",
    "for idx, step in enumerate(seq_plan._steps):\n",
    "    print(f\"Étape {idx+1} => {step.description} // {step.metadata.fully_qualified_name}\")\n",
    "\n",
    "# Exécuter le plan\n",
    "execution_result = await seq_plan.invoke(kernel)\n",
    "print(\"\\n=== Résultat du plan ===\")\n",
    "print(execution_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mémoire & Embeddings\n",
    "\n",
    "**SemanticTextMemory** permet de stocker des textes (avec un embedding) dans un store :\n",
    "- `VolatileMemoryStore` (en mémoire)\n",
    "- ou connecteurs vers Pinecone, Azure Cognitive Search, Qdrant, etc.\n",
    "\n",
    "On peut ensuite effectuer des requêtes sémantiques :  \n",
    "`await memory.search(\"MaCollection\", \"Quelle est mon budget pour 2024 ?\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réponse potentielle :  Budget 2024 = 100k€\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cellule : Extrait Mémoire\n",
    "# ============================\n",
    "\n",
    "from semantic_kernel.memory import SemanticTextMemory, VolatileMemoryStore\n",
    "from semantic_kernel.core_plugins.text_memory_plugin import TextMemoryPlugin\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAITextEmbedding\n",
    "\n",
    "# Embedding service (ex : openai text-embedding-ada)\n",
    "embedding_service = OpenAITextEmbedding(\n",
    "    service_id=\"embeddingService\",\n",
    "    ai_model_id=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "# Volatile in-memory store\n",
    "store = VolatileMemoryStore()\n",
    "memory = SemanticTextMemory(store, embeddings_generator=embedding_service)\n",
    "\n",
    "# Ajouter ce plugin au kernel\n",
    "kernel.add_plugin(TextMemoryPlugin(memory), \"TextMemoryPlugin\")\n",
    "\n",
    "# Stocker quelques infos\n",
    "collection_name = \"testCollection\"\n",
    "await memory.save_information(collection=collection_name, id=\"info1\", text=\"Budget 2024 = 100k€\")\n",
    "await memory.save_information(collection=collection_name, id=\"info2\", text=\"Budget 2023 = 70k€\")\n",
    "\n",
    "# Requête\n",
    "results = await memory.search(collection_name, \"Quel est mon budget pour 2024 ?\", limit=1)\n",
    "print(\"Réponse potentielle : \", results[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face Intégration\n",
    "\n",
    "Semantic Kernel peut se connecter à Hugging Face localement ou via API.  \n",
    "Exemple :  \n",
    "```python\n",
    "from semantic_kernel.connectors.ai.hugging_face import HuggingFaceTextCompletion\n",
    "\n",
    "hf_service = HuggingFaceTextCompletion(\n",
    "    service_id=\"textHF\", ai_model_id=\"distilgpt2\", task=\"text-generation\"\n",
    ")\n",
    "kernel.add_service(hf_service)\n",
    "```\n",
    "\n",
    "Ensuite, on peut enregistrer une fonction sémantique ou invoquer directement `hf_service.get_text_contents(...)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groundedness Checking\n",
    "\n",
    "Pour éviter les “hallucinations” d’un résumé :  \n",
    "1. Extrait la liste d'entités du résumé.  \n",
    "2. Vérifie la correspondance de chaque entité avec le texte source (référence).  \n",
    "3. Retire ou corrige les entités non-fondées.\n",
    "\n",
    "Cela se fait via un plugin “GroundingPlugin” (ex. ExtraitEntities, ReferenceCheckEntities, ExciseEntities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Variable `Symbols.VAR_PREFIX: topic` not found in the KernelArguments\n",
      "Variable `Symbols.VAR_PREFIX: topic` not found in the KernelArguments\n",
      "Variable `Symbols.VAR_PREFIX: example_entities` not found in the KernelArguments\n",
      "Variable `Symbols.VAR_PREFIX: topic` not found in the KernelArguments\n",
      "Variable `Symbols.VAR_PREFIX: topic` not found in the KernelArguments\n",
      "Variable `Symbols.VAR_PREFIX: topic` not found in the KernelArguments\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entités détectées: <entities>\n",
      "- budget: Refers to the financial plan for the year 2024, indicating the amount of money allocated for spending.\n",
      "- euros: The currency used in the budget, representing the monetary unit of the European Union.\n",
      "- Milan: A city in Italy where the speaker resides.\n",
      "</entities>\n",
      "Entités non-fondées: <ungrounded_entities>\n",
      "- Milan\n",
      "</ungrounded_entities>\n",
      "Summary corrigé: Mon budget 2024 est de 200k euros.\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cellule : Groundedness Checking\n",
    "# ============================\n",
    "\n",
    "# Suppose qu'on a un \"grounding_text\" = un texte source\n",
    "grounding_text = \"\"\"\n",
    "Votre budget 2024 est de 100k euros.\n",
    "Vous vivez à Genève.\n",
    "Vous avez investi 50k en actions.\n",
    "\"\"\"\n",
    "\n",
    "# Suppose qu'on a un résumé \"faux\"\n",
    "summary_text = \"\"\"\n",
    "Mon budget 2024 est de 200k euros.\n",
    "J'habite à Milan.\n",
    "\"\"\"\n",
    "\n",
    "plugins_directory = \"./prompt_template_samples/\"\n",
    "\n",
    "# On appelle un plugin (hypothétique) \"GroundingPlugin\" comportant 3 fonctions\n",
    "#   - \"ExtractEntities\"\n",
    "#   - \"ReferenceCheckEntities\"\n",
    "#   - \"ExciseEntities\"\n",
    "grounding_plugin = kernel.add_plugin(parent_directory= plugins_directory, plugin_name=\"GroundingPlugin\")\n",
    "\n",
    "extract_entities = grounding_plugin[\"ExtractEntities\"]\n",
    "check_entities = grounding_plugin[\"ReferenceCheckEntities\"]\n",
    "excise_entities = grounding_plugin[\"ExciseEntities\"]\n",
    "\n",
    "# 1) Extraire entités\n",
    "ext_result = await kernel.invoke(extract_entities, input=summary_text)\n",
    "print(\"Entités détectées:\", ext_result)\n",
    "\n",
    "# 2) Vérifier correspondance\n",
    "check_result = await kernel.invoke(check_entities, input=ext_result.value, reference_context=grounding_text)\n",
    "print(\"Entités non-fondées:\", check_result)\n",
    "\n",
    "# 3) Retirer entités non-fondées du summary\n",
    "excision = await kernel.invoke(excise_entities, input=summary_text, ungrounded_entities=check_result.value)\n",
    "print(\"Summary corrigé:\", excision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Result\n",
    "\n",
    "OpenAI (ou Azure) peut renvoyer plusieurs complétions pour un même prompt.  \n",
    "On paramètre `number_of_responses=3` dans les settings.  \n",
    "Ensuite, `get_text_contents(...)` ou `get_chat_message_contents(...)` renvoie un *tableau* de résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réponse n°1:\n",
      "\n",
      "\n",
      "Pourquoi les chats n'aiment-ils pas l'eau ?\n",
      "\n",
      "Parce que dans leur langue, \"miaou\" signifie \"aïe, ça mouille !\"\n",
      "\n",
      "Réponse n°2:\n",
      "\n",
      "\n",
      "Pourquoi les chats n'aiment pas les jeux de société ? Parce qu'ils préfèrent jouer avec les souris !\n",
      "\n",
      "Réponse n°3:\n",
      "\n",
      "\n",
      "Pourquoi les chats n'aiment-ils pas jouer au poker ? Parce qu'ils préfèrent garder leurs griffes pour le grattage des cartes !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cellule : Multi-Result\n",
    "# ============================\n",
    "\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAITextPromptExecutionSettings\n",
    "\n",
    "settings = OpenAITextPromptExecutionSettings(\n",
    "    extension_data={\n",
    "        \"max_tokens\": 60,\n",
    "        \"temperature\": 0.7,\n",
    "        \"number_of_responses\": 3\n",
    "    }\n",
    ")\n",
    "\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAITextCompletion\n",
    "text_service = OpenAITextCompletion(service_id=\"multiResult\", ai_model_id=\"gpt-3.5-turbo-instruct\")\n",
    "\n",
    "prompt = \"Donne-moi une brève blague sur les chats :\"\n",
    "\n",
    "# get_text_contents() => liste de réponses\n",
    "responses = await text_service.get_text_contents(prompt, settings=settings)\n",
    "\n",
    "for i, r in enumerate(responses):\n",
    "    print(f\"Réponse n°{i+1}:\\n{r}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Nous avons vu :\n",
    "1. Un **Chat** basique avec `KernelArguments`.\n",
    "2. Les **Planners** (Sequential, Stepwise) pour orchestrer dynamiquement des steps.\n",
    "3. La **Mémoire** & embeddings pour stocker/rechercher des informations sémantiques.\n",
    "4. L’**intégration Hugging Face** pour exécuter localement des modèles open-source.\n",
    "5. Un **Groundedness Checking** minimal pour éviter les hallucinations.\n",
    "6. La gestion de **plusieurs réponses** (Multi-Result) avec un seul appel.\n",
    "\n",
    "Ces fonctionnalités permettent de créer des scénarios complexes : chat évolué, question-answering avec mémoire persistante, planification automatique, usage local ou cloud, etc. Bonne exploration !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
